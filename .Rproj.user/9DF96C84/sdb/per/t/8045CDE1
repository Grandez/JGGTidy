{
    "collab_server" : "",
    "contents" : "---\ntitle: \"Getting and cleaning data\"\noutput: github_document\n---\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE)\n```\n\n## Introduction \n\nThe objetive of this program is get ad make tidy som information about the accelerometers from the Samsung Galaxy S smartphone.\n\n\nAll info is provided by: \n[UCI - Machine Learning Repository](http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones)\n\nFiles can be downloaded in zip format, and all information about the data can be found there.\n\n## Assumptions\n\n### About files\n\nAlthough data is splitted into several files, I'm focused on:\n\n\n   - 'features.txt': List of all features.\n   - 'activity_labels.txt': Links the class labels with their activity name.\n   - 'Directory':\n       - 'train/X_train.txt': Training set.\n       - 'train/y_train.txt': Training labels.\n       - 'train/subject_train.txt': Id of subjects\n\nAnd inside the data, only get information about medians and standard deviations\n\nI don't assume anything about data but structure of zipped file and naming conventions, that is:\n\n\n    1.- Activity_labels.txt and features.txt are in root tree\n    2.- There are several folders according the requeriments for the machine learning: train, test, val, ...\n    3.- Each folder has a name (xxx) and contains three files:\n        3.1 subject_xxx.txt Indicating the subject Id\n        3.2 y_xxx.txt Indicating the activity of subject\n        3.3 x_xxx.txt The observations\n\n### About data\n\n * Each windowed observation is defined by the three coordinates: X,Y and Z; so, I assume that values are part of one observation.\n * Each windowed observation stores diferents data: min, max, mean and sd. I think that mean and sd values should be always thogether because they are inter-related: first approach is a table with mean(x,y,z) and sd(x,y,z) values, another approach could be two related tables, one for mean values and the other one for sd, but in this capstone I choosed create a row for each data, adding a column measure to indicate the type of data: \"mean\" or \"sd\"\n\n## Approach\n\nMain features are:\n\n1.- Make the code as abstract(generic) as possible\n2.- Minimize the use of memory\n3.- Minimize readings\n\nThere are two basic process:\n\n    1.- Load the data into memory\n    2.- Make it tidy\n    \n    \n## Load the data\n\nData is loaded directly from Internet or use a previously downloaded file according the prefix of file name (http or not) and it is readed without decompressing.\n\nFlow is:\n\n    1.- loadFile -> get access to file\n    2.- Process features / Select columna names to read in order to avoid read the full data\n    3.- For each directory (train, test, etc)\n        3.1 .- Load subject file\n        3.2 .- Load Y axis\n        3.3 .- Load selected columns from X data\n    4.- Mark Subject and activities as factor\n\nThe relationship between files is:\n \n     +--------+  1    1  +---------+  1    1  +---------+\n     | X_data | <------> | subject | <------> |    Y    |\n     +--------+ By row   +--------+   By row  +---------+\n\nThe resulting dataframe is: \n \n    +---------+----------+-----------------------------+\n    | subject | activity | vector of selected columns  |\n    | subject | activity | vector of selected columns  |\n    |  ...    |    ...   |          ....               |\n    +---------+----------+-----------------------------+\n\n## Tidying the data\n\nOnce data are loaded into memory they are like this:\n\n    +---------+----------+-------------+------------+-------------+---------+---------|----------+-------------------+\n    | subject | activity | tbody_mean_x|tbody_mean_y|tbody_mean_z|tbody_sd_x|body_sd_y|tbody_sd_z|tgravity_sd_x .... |\n    | subject | activity | tbody_mean_x|tbody_mean_y|tbody_mean_z|tbody_sd_x|body_sd_y|tbody_sd_z|tgravity_sd_x .... |\n    |  ...    |    ...   |                                     ....                                                  |\n    +---------+----------+-------------------------------------------------------------------------------------------+\n\nWhere each row has unfriendly names and diferent info.  \nTarget is split the data into groups by: \n    * body/gravity/etc\n    * mean/sd  \n\ngetting a data frame like this:\n    1.- Subject: Id of subject\n    2.- Activity: Factor of activities\n    3.- Object: Measured object: Body, Gravity, ...\n    4.- Measure: Type of data: mean or standard deviation\n    5.- X: X value\n    6.- Y: Y value\n    7.- Z: Z value\n\n\nFlow is:\n\n    1.- for each main pattern (body, gravity, etc.) split the data\n        1.1.- Set the column object to pattern\n        1.2.- For each measure (mean, sd) split the data\n            1.2.1 .- Set the column Measure to its value\n            1.2.2 .- Set the names to X,Y,Z\n            1.2.2 .-  Combine columns subject/activity with the data frame\n        1.3.- Combine rows in a data frame\n        \n",
    "created" : 1491132002778.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3761158373",
    "id" : "8045CDE1",
    "lastKnownWriteTime" : 1491242036,
    "last_content_update" : 1491242036743,
    "path" : "P:/R/DataScience/JGGTidy/man/codebook.md",
    "project_path" : "man/codebook.md",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "markdown"
}